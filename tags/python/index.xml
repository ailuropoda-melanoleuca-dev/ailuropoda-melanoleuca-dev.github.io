<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Python on パンダ好き</title><link>https://ryongyong.github.io/tags/python/</link><description>Recent content in Python on パンダ好き</description><generator>Hugo -- gohugo.io</generator><language>ja</language><lastBuildDate>Mon, 20 Mar 2023 01:50:15 +0900</lastBuildDate><atom:link href="https://ryongyong.github.io/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>データ分析100本ノック(21-30)</title><link>https://ryongyong.github.io/post/study/data_analysis_202303020/</link><pubDate>Mon, 20 Mar 2023 01:50:15 +0900</pubDate><guid>https://ryongyong.github.io/post/study/data_analysis_202303020/</guid><description>ノック21 読み込んでデータ確認 import pandas as pd uselog = pd.read_csv(&amp;#34;../data/use_log.csv&amp;#34;) customer = pd.read_csv(&amp;#34;../data/customer_master.csv&amp;#34;) class_master = pd.read_csv(&amp;#34;../data/class_master.csv&amp;#34;) campaign_master = pd.read_csv(&amp;#34;../data/campaign_master.csv&amp;#34;) print(len(uselog)) uselog.head() customer.head() class_master.head() campaign_master.head() ノック22 それぞれどのキーを使えば良いか考えて、データをマージする customer_join</description></item><item><title>データ分析100本ノック(16-20)</title><link>https://ryongyong.github.io/post/study/data_analysis_202303012/</link><pubDate>Sun, 12 Mar 2023 20:16:06 +0900</pubDate><guid>https://ryongyong.github.io/post/study/data_analysis_202303012/</guid><description>ノック16 顧客名の揺れを補正しよう str.replace()で消す。 kokyaku_data[&amp;#34;顧客名&amp;#34;] = kokyaku_</description></item><item><title>データ分析100本ノック(11-15)</title><link>https://ryongyong.github.io/post/study/data_analysis_20230307/</link><pubDate>Tue, 07 Mar 2023 00:24:42 +0900</pubDate><guid>https://ryongyong.github.io/post/study/data_analysis_20230307/</guid><description>既に10本単位じゃなくなってるのウケるな。 今回は少しのデータクレンジングを体験する感じ。 ノック11/12 データを読み込んでみよう/データの揺</description></item><item><title>データ分析100本ノック(1-10)</title><link>https://ryongyong.github.io/post/study/data_analysis_20230306/</link><pubDate>Mon, 06 Mar 2023 19:36:48 +0900</pubDate><guid>https://ryongyong.github.io/post/study/data_analysis_20230306/</guid><description>なんで今更？と思うかもしれないが、家に積読されているのを発見したので、10本ずつノックしていく。 毎日10本ノックすれば10日で終わる(計画性</description></item><item><title>Open3DでHarris特徴量を計算する</title><link>https://ryongyong.github.io/post/study/open3d-harris3d/</link><pubDate>Thu, 02 Mar 2023 15:55:42 +0900</pubDate><guid>https://ryongyong.github.io/post/study/open3d-harris3d/</guid><description>Harris-3D 二次元画像処理ではHarris特徴量の計算は割とよくやる。 Harrisのコーナー検出 輝度値や明度値にした画像にフィルターを縦横に移動させな</description></item><item><title>Open3Dを用いた法線推定</title><link>https://ryongyong.github.io/post/study/open3d-normals/</link><pubDate>Mon, 27 Feb 2023 11:47:53 +0900</pubDate><guid>https://ryongyong.github.io/post/study/open3d-normals/</guid><description>今回もOpen3Dを使ったお遊び試行として、スタンフォードバニーの法線推定をしてみた。 法線は点群の位置合わせや、画像認識時の特徴量として重要</description></item><item><title>Open3Dのサンプリング</title><link>https://ryongyong.github.io/post/study/open3d-samping/</link><pubDate>Thu, 23 Feb 2023 20:12:26 +0900</pubDate><guid>https://ryongyong.github.io/post/study/open3d-samping/</guid><description>Open3Dを使っていくつかのサンプリング手法を試してみた。 Voxel Down Sampling Random Sampling Farthest Point Sampling Poisson Disk Sampling 使った点群データはスタンフォードバニーちゃん Voxel Down Sampling ボクセル</description></item></channel></rss>